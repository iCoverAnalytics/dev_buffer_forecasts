{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5392eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stepchenko.Ilja\\AppData\\Local\\anaconda3\\Lib\\site-packages\\airflow\\__init__.py:36: RuntimeWarning: Airflow currently can be run on POSIX-compliant Operating Systems. For development, it is regularly tested on fairly modern Linux Distros and recent versions of macOS. On Windows you can run it via WSL2 (Windows Subsystem for Linux 2) or via Linux Containers. The work to add Windows support is tracked via https://github.com/apache/airflow/issues/10388, but it is not a high priority.\n",
      "  warnings.warn(\n",
      "OSError while attempting to symlink the latest log directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-19T18:08:49.233+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m54} INFO\u001b[0m - Конфиги для БД загружены из окружения.\u001b[0m\n",
      "[\u001b[34m2025-08-19T18:08:49.293+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m59} INFO\u001b[0m - Локальное подключение к ClickHouse установлено.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import logging\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import sys\n",
    "sys.path.append(r'\\\\sigma.icover.ru\\share\\Аналитика\\Скрипты\\Сливин\\plugins')\n",
    "from ConnectingOperator import ClickHouseConnector\n",
    "from preprocess_data_2 import preprocess_data # type: ignore\n",
    "ch_object = ClickHouseConnector(task_id='my_buffers', local_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09e8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = {\n",
    "    'id_ver': 'int64',\n",
    "    'date': 'datetime64[ns]',\n",
    "    'name': 'string',   \n",
    "    'article_1c': 'string',\n",
    "    'code_1c': 'string',\n",
    "    'mp': 'string',\n",
    "    'seller': 'string',\n",
    "    'sku': 'string',\n",
    "    'cluster_to': 'string',\n",
    "    'total_quantity_orders': 'int64',\n",
    "    'max_quantity_order': 'int64',\n",
    "    'avg_quantity_orders': 'float64',\n",
    "    'days_oos_number': 'int64',\n",
    "    'days_bp_number': 'int64',    \n",
    "    'avg_day_to_cluster': 'int64',\n",
    "    'insurance_reserv_cluster': 'int64',\n",
    "    'buffer_cluster_norm': 'int64',\n",
    "    'buffer_cluster': 'int64',\n",
    "    'deliveries_to_cluster': 'int64',\n",
    "    'buffer_cluster_marker': 'float64',\n",
    "    'quantity_orders': 'int64',\n",
    "    'quantity_stocks': 'int64',\n",
    "    'quantity_supplies': 'int64',\n",
    "    'new_buffer': 'int64',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe400c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2025-02-01'\n",
    "PARAMS = {\n",
    "    # --- БАЗА (остается как у тебя) ---\n",
    "    'PERIOD': 30,                 # окно истории продаж для расчётов (дни) - используется для init dayи используется в т.ч. (пока нет товарной матрицы) для определения пула на расчета буфера\n",
    "    'AVG_DAYS_CONST': 7,          # дефолтный RT (дней), пока нет фактического по ключу\n",
    "    'OOS_RATIO': 0.02,            # порог \"низкий запас\" (для аналитики/отчетов, не влияет на ДУБ)\n",
    "    'BAD_PRICE_LOW': -0.4,        # нижний порог \"плохой\" цены (для аналитики; SUSPEND пока не используем)\n",
    "    'BAD_PRICE_HIGH': 0.4,        # верхний порог \"плохой\" цены\n",
    "    'MAX_EXCLUDED_SHARE': 0.2,    # доля исключаемых дней при расчете ADU (используем позже в rebase)\n",
    "    'INS_CONST': 0,               # страховой резерв (для rebase/целевого BT; не в ДУБ)\n",
    "    'BUF_NORM_CONST': 28,         # норматив буфера (для rebase; не в ДУБ) (AVG_DAYS_CONST * M_RT)\n",
    "    'id_ver': 2 ,                 # версия расчёта\n",
    "    'min_cluster_m3': 8,          # минимальный объем товаров на кластер\n",
    "    'min_good': 3,                # минимальное количество товаров на поставку\n",
    "    'min_cluster_limit': 6,       # добавлено потом: максимальный объем, при котором все равно грузим последнюю машину\n",
    "\n",
    "    # --- ДУБ / ЕГОРОВ: ОКНО НАБЛЮДЕНИЯ ---\n",
    "    'M_RT': 4,                    # множитель к RT: окно = RT * M_RT (на каждый ключ)\n",
    "\n",
    "    # --- ДУБ: ПРАВИЛА РЕШЕНИЯ (ежедневно) ---\n",
    "    'RED_SHARE_UP': 1/3,          # UP, если красных >= 1/3 наблюдаемых дней в окне\n",
    "    'GREEN_SHARE_DOWN': 2/3,      # DOWN, если зеленых >= 2/3 и нет красн/черн\n",
    "    'REQUIRE_COVERAGE': 0.6,      # мин. доля календарных дней с валидной зоной в окне; иначе HOLD\n",
    "    'FAST_RED_STREAK': 3,         # быстрый триггер UP: N подряд дней \"красных\" в конце окна\n",
    "\n",
    "    # --- ИНТЕРПРЕТАЦИЯ ПОСТАВОК ДЛЯ Available ---\n",
    "    'RECEIVING_DAYS': 0,          # если приемка/разблокировка не входит в RT, поставь реальное значение (>0) (пока не используем для упрощения)\n",
    "    'INCLUDE_BOUNDARY': 1,        # включать поставки с saleable_date == t+RT в InboundWithinRT\n",
    "\n",
    "    # --- SUSPEND (временно выключен) ---\n",
    "    'USE_SUSPEND': 0,             # до появления Товарной матрицы SUSPEND не применяем\n",
    "    # 'SUSPEND_HARD': ['listing_block','stop_supply','hard_quarantine'],   # зарезервировано\n",
    "    # 'SUSPEND_SOFT_DOWN': ['bad_price'],                                   # зарезервировано\n",
    "    # 'SUSPEND_TTL_DAYS': 30,\n",
    "    # 'SUSPEND_AUTORELEASE_DAYS': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc77a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_keys  = f'''\n",
    "WITH\n",
    "    {PARAMS['PERIOD']}       AS PERIOD,\n",
    "    {PARAMS['RECALC_EVERY']} AS RECALC_EVERY,\n",
    "    {PARAMS['id_ver']}       AS CUR_VER\n",
    "\n",
    ", keys_from_sales AS (\n",
    "    SELECT DISTINCT mp, seller, sku, article_1c, code_1c, cluster_to\n",
    "    FROM kpi.all_mp_sales_wsb\n",
    "    WHERE toDate(date) >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND toDate(date) <  toDate('{START_DATE}')\n",
    ")\n",
    "\n",
    ", keys_from_sim_yesterday AS (\n",
    "    SELECT DISTINCT mp, seller, sku, article_1c, code_1c, cluster_to\n",
    "    FROM sb.buffer_main\n",
    "    WHERE date   = toDate('{START_DATE}') - INTERVAL 1 DAY\n",
    "      AND id_ver = CUR_VER\n",
    ")\n",
    "\n",
    ", keys_today AS (\n",
    "    SELECT * FROM keys_from_sales\n",
    "    UNION DISTINCT\n",
    "    SELECT * FROM keys_from_sim_yesterday\n",
    ")\n",
    "\n",
    "/* валидные артикулы только для нужных МП */\n",
    ", valid_articles AS (\n",
    "    SELECT DISTINCT article_1c, code_1c, sku, mp\n",
    "    FROM ref.article_mp\n",
    "    WHERE discounted != 1\n",
    "      AND brand != 'РЕСЕЙЛ'\n",
    "      AND mp IN ('Ozon','WB','YM')\n",
    ")\n",
    "\n",
    "/* есть ли ХОТЬ КАКАЯ история по текущей версии ДО D (а не только на D-1) */\n",
    ", hist_before_today AS (\n",
    "    SELECT\n",
    "        mp, seller, sku, article_1c, code_1c, cluster_to,\n",
    "        count() AS cnt_hist\n",
    "    FROM sb.buffer_main\n",
    "    WHERE toDate(date) < toDate('{START_DATE}')\n",
    "      AND id_ver = CUR_VER\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    "/* состояние именно на D-1 в текущей версии (для recalc/second) */\n",
    ", prev_state AS (\n",
    "    SELECT\n",
    "        mp, seller, sku, article_1c, code_1c, cluster_to,\n",
    "        max(toInt16(new_buffer)) AS new_buffer_prev\n",
    "    FROM sb.buffer_main\n",
    "    WHERE date   = toDate('{START_DATE}') - INTERVAL 1 DAY\n",
    "      AND id_ver = CUR_VER\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    toDate('{START_DATE}') AS date,\n",
    "    kt.mp        AS mp,\n",
    "    kt.seller    AS seller,\n",
    "    kt.sku       AS sku,\n",
    "    kt.article_1c AS article_1c,\n",
    "    kt.code_1c    AS code_1c,\n",
    "    kt.cluster_to AS cluster_to,\n",
    "\n",
    "    /* ПРИОРИТЕТ: если нет ИСТОРИИ до D → first_init;\n",
    "       иначе если на D-1 счётчик на пересчёт → recalc_day;\n",
    "       иначе → simulate_day */\n",
    "    multiIf(\n",
    "        hist.cnt_hist IS NULL OR hist.cnt_hist = 0,           'first_init',\n",
    "        p.new_buffer_prev >= (RECALC_EVERY - 1),              'recalc_day',\n",
    "                                                              'simulate_day'\n",
    "    ) AS calc_type,\n",
    "\n",
    "    p.new_buffer_prev AS new_buffer_prev,\n",
    "    CAST(hist.cnt_hist IS NULL OR hist.cnt_hist = 0 AS UInt8) AS is_first_day,\n",
    "    CAST(p.new_buffer_prev >= (RECALC_EVERY - 1)\n",
    "         AND p.new_buffer_prev IS NOT NULL AS UInt8)          AS is_recalc_day,\n",
    "    CAST(CUR_VER AS UInt8)                               AS id_ver\n",
    "\n",
    "FROM keys_today kt\n",
    "INNER JOIN valid_articles va\n",
    "    ON  kt.article_1c = va.article_1c\n",
    "    AND kt.code_1c    = va.code_1c\n",
    "    AND kt.sku        = va.sku\n",
    "    AND kt.mp         = va.mp\n",
    "LEFT JOIN hist_before_today hist\n",
    "    ON  kt.mp         = hist.mp\n",
    "    AND kt.seller     = hist.seller\n",
    "    AND kt.sku        = hist.sku\n",
    "    AND kt.article_1c = hist.article_1c\n",
    "    AND kt.code_1c    = hist.code_1c\n",
    "    AND kt.cluster_to = hist.cluster_to\n",
    "LEFT JOIN prev_state p\n",
    "    ON  kt.mp         = p.mp\n",
    "    AND kt.seller     = p.seller\n",
    "    AND kt.sku        = p.sku\n",
    "    AND kt.article_1c = p.article_1c\n",
    "    AND kt.code_1c    = p.code_1c\n",
    "    AND kt.cluster_to = p.cluster_to\n",
    "GROUP BY\n",
    "    date, mp, seller, sku, article_1c, code_1c, cluster_to,\n",
    "    calc_type, new_buffer_prev, is_first_day, is_recalc_day, id_ver\n",
    "        '''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f167ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:42.058+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m78} INFO\u001b[0m - Получение данных из БД\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:42.735+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m81} INFO\u001b[0m - Получено 30251 строк.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_keys = ch_object.extract_data(query_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2719514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:42.748+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m140} INFO\u001b[0m - Выполнение произвольного запроса: ALTER TABLE sb.buffer_calc_keys DELETE WHERE id_ver = 1 AND date = '2025-02-08'  \u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:42.762+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m91} INFO\u001b[0m - Вставка 30251 записей в sb.buffer_calc_keys.\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:43.048+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m97} INFO\u001b[0m - Таблица sb.buffer_calc_keys содержит 332255 строк после вставки.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ch_object.execute_query(query=f'''ALTER TABLE sb.buffer_calc_keys DELETE WHERE id_ver = {PARAMS['id_ver']} AND date = '{START_DATE}'  ''')\n",
    "ch_object.insert_data(table_name='sb.buffer_calc_keys', df=df_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd95483",
   "metadata": {},
   "source": [
    "Наполняем buffer_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15fafeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:43.066+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m140} INFO\u001b[0m - Выполнение произвольного запроса: ALTER TABLE sb.buffer_main DELETE WHERE id_ver = 1 AND date = '2025-02-08'  \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 7558741, '25b4ca53-8a3a-4a4f-82b3-a3ff8b3899e2']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_object.execute_query(query=f'''ALTER TABLE sb.buffer_main DELETE WHERE id_ver = {PARAMS['id_ver']} AND date = '{START_DATE}'  ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed70cec",
   "metadata": {},
   "source": [
    "Инициация буфера (first_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fbc8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_init  = f'''\n",
    "WITH\n",
    "    toInt32({PARAMS['PERIOD']})               AS PERIOD,\n",
    "    toInt32({PARAMS['RECALC_EVERY']})         AS RECALC_EVERY,\n",
    "    toFloat64({PARAMS['OOS_RATIO']})          AS OOS_RATIO,\n",
    "    toFloat64({PARAMS['BAD_PRICE_LOW']})      AS BAD_PRICE_LOW,\n",
    "    toFloat64({PARAMS['BAD_PRICE_HIGH']})     AS BAD_PRICE_HIGH,\n",
    "    toFloat64({PARAMS['MAX_EXCLUDED_SHARE']}) AS MAX_EXCLUDED_SHARE,\n",
    "    toInt32({PARAMS['AVG_DAYS_CONST']})       AS AVG_DAYS_CONST,\n",
    "    toInt32({PARAMS['INS_CONST']})            AS INS_CONST,\n",
    "    toInt32({PARAMS['BUF_NORM_CONST']})       AS BUF_NORM_CONST,\n",
    "    toInt32({PARAMS['id_ver']})               AS CUR_VER\n",
    "\n",
    ", key_list_prime AS (\n",
    "    SELECT DISTINCT mp, seller, sku, article_1c, code_1c, cluster_to\n",
    "    FROM sb.buffer_calc_keys\n",
    "    WHERE date = toDate('{START_DATE}')\n",
    "      AND id_ver = CUR_VER\n",
    "      AND calc_type = 'first_init'\n",
    ")\n",
    "\n",
    ", supplies AS (\n",
    "    SELECT s.mp AS mp, s.seller AS seller, s.article_1c AS article_1c, s.code_1c AS code_1c,\n",
    "           cluster_to AS cluster_to, SUM(s.quantity_supplies) AS quantity_supplies\n",
    "    FROM sb.buffer_supplies s\n",
    "    WHERE s.shipping_date < toDate('{START_DATE}') AND s.closing_date > toDate('{START_DATE}')\n",
    "    GROUP BY s.mp, s.seller, s.article_1c, s.code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", stocks_mp AS (\n",
    "    SELECT s.date, s.mp AS mp, s.seller AS seller, s.sku AS sku, s.article_1c AS article_1c, s.code_1c AS code_1c,\n",
    "           rwh.cluster_to AS cluster_to,\n",
    "           SUM(s.quantityFree) AS quantity_stocks,\n",
    "           SUM(s.quantityFull) AS quantity_stocks_full\n",
    "    FROM goods.stocks s\n",
    "    LEFT JOIN (SELECT DISTINCT mp, warehouse_name, cluster AS cluster_to FROM ref.warehouses) rwh\n",
    "      ON rwh.warehouse_name = s.warehouse_name AND rwh.mp = s.mp\n",
    "    WHERE s.date >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND s.date <= toDate('{START_DATE}')\n",
    "      AND s.mp IN ('WB','Ozon','YM')\n",
    "      AND s.quantityFree > 0\n",
    "      AND s.code_1c != ''\n",
    "    GROUP BY s.date, s.mp, s.seller, s.sku, s.article_1c, s.code_1c, rwh.cluster_to\n",
    ")\n",
    "\n",
    ", stocks_1c AS (\n",
    "    SELECT st.date, st.article_1c, st.code_1c,\n",
    "           SUM(st.quantityFree) AS quantity_stocks_main,\n",
    "           SUM(st.quantityFull) AS quantity_stocks_main_full\n",
    "    FROM goods.stocks st\n",
    "    WHERE st.date >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND st.date <= toDate('{START_DATE}')\n",
    "      AND st.warehouse_name IN ('Основной','Старая Купавна ответ хранение (СТ Лоджистик)','Старая Купавна: СВХ','Старая Купавна')\n",
    "      AND st.mp = '1C'\n",
    "      AND st.quantityFree > 0\n",
    "      AND st.code_1c != ''\n",
    "    GROUP BY st.date, st.article_1c, st.code_1c\n",
    ")\n",
    "\n",
    ", stocks_on_cluster_to AS (\n",
    "    SELECT toDate(smp.date) AS date,\n",
    "           smp.mp AS mp, smp.seller AS seller, smp.sku AS sku,\n",
    "           smp.article_1c AS article_1c, smp.code_1c AS code_1c,\n",
    "           smp.cluster_to AS cluster_to,\n",
    "           SUM(smp.quantity_stocks) AS quantity_stocks\n",
    "    FROM stocks_mp smp\n",
    "    INNER JOIN key_list_prime\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE toDate(smp.date) >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND toDate(smp.date)  < toDate('{START_DATE}')\n",
    "    GROUP BY date, mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", keys AS (\n",
    "    SELECT DISTINCT mp, seller, sku, article_1c, code_1c, cluster_to\n",
    "    FROM stocks_on_cluster_to\n",
    ")\n",
    "\n",
    ", calendar AS (\n",
    "    SELECT am.date, k.mp, k.seller, k.sku, k.article_1c, k.code_1c, k.cluster_to\n",
    "    FROM ref.calendar am\n",
    "    CROSS JOIN keys k\n",
    "    WHERE am.date >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND am.date  <  toDate('{START_DATE}')\n",
    ")\n",
    "\n",
    ", max_stocks_per_cluster AS (\n",
    "    SELECT mp, seller, sku, article_1c, code_1c, cluster_to,\n",
    "           MAX(quantity_stocks) AS max_qs\n",
    "    FROM stocks_on_cluster_to\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", days_oos AS (\n",
    "    SELECT cal.date AS date, cal.mp AS mp, cal.seller AS seller, cal.sku AS sku,\n",
    "           cal.article_1c AS article_1c, cal.code_1c AS code_1c, cal.cluster_to AS cluster_to,\n",
    "           'Низкий запас' AS out_of_stocks,\n",
    "           am.quantity_stocks AS quantity_stocks,\n",
    "           ms.max_qs AS max_qs\n",
    "    FROM calendar cal\n",
    "    LEFT JOIN stocks_on_cluster_to am\n",
    "        USING (date, mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    LEFT JOIN max_stocks_per_cluster ms\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE ifNull(am.quantity_stocks, 0) <= 0\n",
    "       OR (ifNull(am.quantity_stocks, 0) / nullIf(ms.max_qs, 0)) <= OOS_RATIO\n",
    ")\n",
    "\n",
    ", orders_per_cluster_prime AS (\n",
    "    SELECT am.date AS date, am.mp AS mp, am.seller AS seller, am.sku AS sku,\n",
    "           am.article_1c AS article_1c, am.code_1c AS code_1c, am.cluster_to AS cluster_to,\n",
    "           SUM(am.quantity_orders) AS quantity_orders,\n",
    "           SUM(am.orders_sum) AS orders_sum,\n",
    "           SUM(am.cost_value_orders) AS cost_value_orders\n",
    "    FROM kpi.all_mp_sales_wsb am\n",
    "    INNER JOIN key_list_prime USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE am.date >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND am.date <= toDate('{START_DATE}')\n",
    "      AND am.quantity_orders != 0\n",
    "    GROUP BY am.date, am.mp, am.seller, am.sku, am.article_1c, am.code_1c, am.cluster_to\n",
    ")\n",
    "\n",
    ", median_price_by_key AS (\n",
    "    SELECT mp, seller, sku, article_1c, code_1c, cluster_to,\n",
    "           median(orders_sum/quantity_orders) AS median_price\n",
    "    FROM orders_per_cluster_prime\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", main AS (\n",
    "  SELECT cal.date AS date, cal.mp AS mp, cal.seller AS seller, cal.sku AS sku,\n",
    "         cal.article_1c AS article_1c, cal.code_1c AS code_1c, cal.cluster_to AS cluster_to,\n",
    "         am.out_of_stocks AS out_of_stocks,\n",
    "         ms.quantity_orders AS quantity_orders,\n",
    "         ms.orders_sum AS orders_sum,\n",
    "         ms.cost_value_orders AS cost_value_orders,\n",
    "         (ms.orders_sum/ms.quantity_orders) AS avg_price_per_day,\n",
    "         (ms.cost_value_orders/ms.quantity_orders) AS avg_cost,\n",
    "         mpk.median_price,\n",
    "         (avg_price_per_day/mpk.median_price - 1) AS rate,\n",
    "         IF(rate<=BAD_PRICE_LOW, 'Низкая цена', IF(rate>=BAD_PRICE_HIGH, 'Высокая цена', '')) AS bad_price\n",
    "  FROM calendar cal\n",
    "  LEFT JOIN orders_per_cluster_prime AS ms\n",
    "    USING (date, mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "  LEFT JOIN days_oos AS am\n",
    "    USING (date, mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "  LEFT JOIN median_price_by_key mpk\n",
    "    USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    ")\n",
    "\n",
    ", days_oos_number AS (\n",
    "    SELECT mp, seller, sku, article_1c, code_1c, cluster_to, count(*) AS days_oos_number\n",
    "    FROM main\n",
    "    WHERE out_of_stocks = 'Низкий запас'\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", bad_price_number AS (\n",
    "    SELECT mp, seller, sku, article_1c, code_1c, cluster_to,\n",
    "           SUM(quantity_orders) AS bp_quantity_orders, count(*) AS days_bp_number\n",
    "    FROM main\n",
    "    WHERE bad_price = 'Низкая цена'\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", exclude_number AS (\n",
    "    SELECT mp, seller, sku, article_1c, code_1c, cluster_to, count(*) AS exclude_number\n",
    "    FROM main\n",
    "    WHERE out_of_stocks = 'Низкий запас' OR bad_price = 'Низкая цена'\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", import AS (\n",
    "    SELECT code_1c, article_1c, SUM(quantity) AS quantity_import_orders\n",
    "    FROM goods.import_supplies\n",
    "    GROUP BY code_1c, article_1c\n",
    ")\n",
    "\n",
    ", insurance AS (\n",
    "    SELECT mp, seller, sku, article_1c, code_1c, cluster_to, stddevPop(f.quantity_orders) AS sigma\n",
    "    FROM main f\n",
    "    GROUP BY mp, seller, sku, article_1c, code_1c, cluster_to\n",
    ")\n",
    "\n",
    ", final_full AS (\n",
    "    SELECT am.mp AS mp, am.seller AS seller, am.sku AS sku, am.article_1c AS article_1c, am.code_1c AS code_1c, am.cluster_to AS cluster_to,\n",
    "           don.days_oos_number, bp.days_bp_number,\n",
    "           smp.quantity_stocks,\n",
    "           smp.quantity_stocks_full,\n",
    "           src.quantity_stocks_main,\n",
    "           src.quantity_stocks_main_full,\n",
    "           sup.quantity_supplies,\n",
    "           bp.bp_quantity_orders,\n",
    "           MAX(am.quantity_orders) AS max_quantity_order,\n",
    "           MIN(am.quantity_orders) AS min_quantity_order,\n",
    "           SUM(am.quantity_orders) AS total_quantity_orders_full,\n",
    "           SUM(am.quantity_orders)/PERIOD AS avg_quantity_orders_full\n",
    "    FROM main am\n",
    "    LEFT JOIN days_oos_number don USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    LEFT JOIN bad_price_number bp USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    LEFT JOIN supplies sup      USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "    LEFT JOIN stocks_mp smp\n",
    "      ON am.mp=smp.mp AND am.seller=smp.seller AND am.sku=smp.sku\n",
    "     AND am.article_1c=smp.article_1c AND am.code_1c=smp.code_1c\n",
    "     AND am.cluster_to=smp.cluster_to AND smp.date=toDate('{START_DATE}')\n",
    "    LEFT JOIN stocks_1c src\n",
    "      ON am.article_1c=src.article_1c AND am.code_1c=src.code_1c AND src.date=toDate('{START_DATE}')\n",
    "    GROUP BY am.mp, am.seller, am.sku, am.article_1c, am.code_1c, am.cluster_to,\n",
    "             don.days_oos_number, bp.days_bp_number,\n",
    "             smp.quantity_stocks, smp.quantity_stocks_full,\n",
    "             src.quantity_stocks_main, src.quantity_stocks_main_full,\n",
    "             sup.quantity_supplies, bp.bp_quantity_orders\n",
    ")\n",
    "\n",
    ", final_exclude AS (\n",
    "    SELECT am.mp AS mp, am.seller AS seller, am.sku AS sku, am.article_1c AS article_1c, am.code_1c AS code_1c, am.cluster_to AS cluster_to,\n",
    "           ms.quantity_orders AS quantity_orders,\n",
    "           SUM(am.quantity_orders) AS total_quantity_orders,\n",
    "           SUM(am.quantity_orders)/(PERIOD - ex.exclude_number) AS avg_quantity_orders\n",
    "    FROM main am\n",
    "    LEFT JOIN exclude_number ex\n",
    "      ON am.mp=ex.mp AND am.seller=ex.seller AND am.sku=ex.sku\n",
    "     AND am.article_1c=ex.article_1c AND am.code_1c=ex.code_1c AND am.cluster_to=ex.cluster_to\n",
    "    LEFT JOIN orders_per_cluster_prime ms\n",
    "      ON am.date = ms.date AND am.mp = ms.mp AND am.seller = ms.seller\n",
    "     AND am.sku = ms.sku AND am.article_1c = ms.article_1c AND am.code_1c = ms.code_1c\n",
    "     AND am.cluster_to = ms.cluster_to AND ms.date=toDate('{START_DATE}')\n",
    "    WHERE am.date >= toDate('{START_DATE}') - INTERVAL PERIOD DAY\n",
    "      AND am.date  < toDate('{START_DATE}')\n",
    "      AND (am.out_of_stocks != 'Низкий запас' AND bad_price != 'Низкая цена')\n",
    "    GROUP BY am.mp, am.seller, am.sku, am.article_1c, am.code_1c, am.cluster_to, ex.exclude_number, ms.quantity_orders\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    CUR_VER                           AS id_ver,\n",
    "    toDate('{START_DATE}')            AS date,\n",
    "    r.name                            AS name,\n",
    "    article_1c                        AS article_1c,\n",
    "    code_1c                           AS code_1c,\n",
    "    mp                                AS mp,\n",
    "    seller                            AS seller,\n",
    "    sku                               AS sku,\n",
    "    cluster_to                        AS cluster_to,\n",
    "\n",
    "    oos.total_quantity_orders         AS total_quantity_orders,\n",
    "    max_quantity_order                AS max_quantity_order,\n",
    "    ROUND(oos.avg_quantity_orders, 2) AS avg_quantity_orders,\n",
    "    days_oos_number                   AS days_oos_number,\n",
    "    days_bp_number                    AS days_bp_number,\n",
    "\n",
    "    AVG_DAYS_CONST                    AS avg_day_to_cluster,\n",
    "    INS_CONST                         AS insurance_reserv_cluster,\n",
    "    BUF_NORM_CONST                    AS buffer_cluster_norm,\n",
    "\n",
    "    ROUND(BUF_NORM_CONST * avg_quantity_orders) AS buffer_cluster,\n",
    "    greatest(0, ROUND((BUF_NORM_CONST * avg_quantity_orders) - quantity_stocks - quantity_supplies)) AS deliveries_to_cluster,\n",
    "    ROUND(LEAST(IFNULL((quantity_stocks + quantity_supplies) / NULLIF(BUF_NORM_CONST * avg_quantity_orders, 0), 1), 1), 2) AS buffer_cluster_marker,\n",
    "\n",
    "    oos.quantity_orders               AS quantity_orders,\n",
    "    quantity_stocks                   AS quantity_stocks,\n",
    "    quantity_supplies                 AS quantity_supplies,\n",
    "    0                                 AS new_buffer\n",
    "\n",
    "FROM final_full\n",
    "LEFT JOIN final_exclude oos USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "LEFT JOIN (\n",
    "    SELECT DISTINCT name, article_1c, code_1c\n",
    "    FROM ref.article_mp\n",
    "    WHERE discounted != 1 AND brand != 'РЕСЕЙЛ'\n",
    ") r USING (article_1c, code_1c)\n",
    "WHERE days_oos_number <= (PERIOD - PERIOD/6)\n",
    "  AND days_bp_number  <= (PERIOD - PERIOD/6)\n",
    "  AND total_quantity_orders != 0\n",
    "\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a7a0547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:43.112+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m78} INFO\u001b[0m - Получение данных из БД\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:58.868+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m81} INFO\u001b[0m - Получено 941 строк.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_init = ch_object.extract_data(query_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03372e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:58.905+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m91} INFO\u001b[0m - Вставка 941 записей в sb.buffer_main.\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:58.940+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m97} INFO\u001b[0m - Таблица sb.buffer_main содержит 9060 строк после вставки.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_init, other_column_list = preprocess_data(df=df_init, column_types=TYPES, add_missed_columns=False, handle_invalid_values=False)\n",
    "ch_object.insert_data(table_name='sb.buffer_main', df=df_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4a66b",
   "metadata": {},
   "source": [
    "Симуляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad8675b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sim  = f'''\n",
    "/* ---- simulate_day ---- */\n",
    "WITH\n",
    "    toInt32({PARAMS['PERIOD']})               AS PERIOD,\n",
    "    toInt32({PARAMS['RECALC_EVERY']})         AS RECALC_EVERY,\n",
    "    toFloat64({PARAMS['OOS_RATIO']})          AS OOS_RATIO,\n",
    "    toFloat64({PARAMS['BAD_PRICE_LOW']})      AS BAD_PRICE_LOW,\n",
    "    toFloat64({PARAMS['BAD_PRICE_HIGH']})     AS BAD_PRICE_HIGH,\n",
    "    toFloat64({PARAMS['MAX_EXCLUDED_SHARE']}) AS MAX_EXCLUDED_SHARE,\n",
    "    toInt32({PARAMS['AVG_DAYS_CONST']})       AS AVG_DAYS_CONST,\n",
    "    toInt32({PARAMS['INS_CONST']})            AS INS_CONST,\n",
    "    toInt32({PARAMS['BUF_NORM_CONST']})       AS BUF_NORM_CONST,\n",
    "    toInt32({PARAMS['id_ver']})               AS CUR_VER\n",
    "\n",
    "/* ключи для simulate_day */\n",
    ", key_list_second AS (\n",
    "    SELECT DISTINCT mp, seller, sku, article_1c, code_1c, cluster_to\n",
    "    FROM sb.buffer_calc_keys\n",
    "    WHERE date   = toDate('{START_DATE}')\n",
    "      AND id_ver = CUR_VER\n",
    "      AND calc_type = 'simulate_day'\n",
    ")\n",
    "\n",
    "/* состояние на вчера: переносим метрики и увеличиваем счётчик new_buffer */\n",
    ", current_buffer AS (\n",
    "    SELECT\n",
    "        cb.article_1c                AS article_1c,\n",
    "        cb.code_1c                   AS code_1c,\n",
    "        cb.mp                        AS mp,\n",
    "        cb.seller                    AS seller,\n",
    "        cb.sku                       AS sku,\n",
    "        cb.cluster_to                AS cluster_to,\n",
    "        cb.total_quantity_orders     AS total_quantity_orders,\n",
    "        cb.max_quantity_order        AS max_quantity_order,\n",
    "        cb.avg_quantity_orders       AS avg_quantity_orders,\n",
    "        cb.days_oos_number           AS days_oos_number,\n",
    "        cb.days_bp_number            AS days_bp_number,\n",
    "        cb.avg_day_to_cluster        AS avg_day_to_cluster,\n",
    "        cb.insurance_reserv_cluster  AS insurance_reserv_cluster,\n",
    "        cb.buffer_cluster_norm       AS buffer_cluster_norm,\n",
    "        cb.buffer_cluster            AS buffer_cluster,\n",
    "        cb.quantity_stocks           AS quantity_stocks_prev,\n",
    "        cb.quantity_orders           AS quantity_orders_prev,\n",
    "        cb.new_buffer + 1            AS new_buffer\n",
    "    FROM sb.buffer_main cb\n",
    "    INNER JOIN key_list_second\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE cb.date   = toDate('{START_DATE}') - INTERVAL 1 DAY\n",
    "      AND cb.id_ver = CUR_VER\n",
    ")\n",
    "\n",
    "/* продажи на день D */\n",
    ", orders_per_cluster_second AS (\n",
    "    SELECT\n",
    "        am.date         AS date,\n",
    "        am.mp           AS mp,\n",
    "        am.seller       AS seller,\n",
    "        am.sku          AS sku,\n",
    "        am.article_1c   AS article_1c,\n",
    "        am.code_1c      AS code_1c,\n",
    "        am.cluster_to   AS cluster_to,\n",
    "        SUM(am.quantity_orders) AS quantity_orders\n",
    "    FROM kpi.all_mp_sales_wsb am\n",
    "    INNER JOIN key_list_second\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE am.date = toDate('{START_DATE}')\n",
    "    GROUP BY am.date, am.mp, am.seller, am.sku, am.article_1c, am.code_1c, am.cluster_to\n",
    ")\n",
    "\n",
    "/* поставки, прибывающие в день D (для эволюции запасов) */\n",
    ", supplies_arrive_today AS (\n",
    "    SELECT s.mp AS mp, s.seller AS seller, s.article_1c AS article_1c, s.code_1c AS code_1c,\n",
    "           s.cluster_to AS cluster_to,\n",
    "           SUM(s.quantity_supplies) AS quantity_supplies_arrive\n",
    "    FROM sb.buffer_supplies s\n",
    "    INNER JOIN key_list_second\n",
    "        USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "    WHERE s.closing_date = toDate('{START_DATE}')\n",
    "      AND s.shipping_date <= toDate('{START_DATE}')\n",
    "    GROUP BY s.mp, s.seller, s.article_1c, s.code_1c, s.cluster_to\n",
    ")\n",
    "\n",
    "/* поставки в пути на день D (для маркера/потребности) */\n",
    ", supplies_in_transit AS (\n",
    "    SELECT s.mp AS mp, s.seller AS seller, s.article_1c AS article_1c, s.code_1c AS code_1c,\n",
    "           s.cluster_to AS cluster_to,\n",
    "           SUM(s.quantity_supplies) AS quantity_supplies\n",
    "    FROM sb.buffer_supplies s\n",
    "    INNER JOIN key_list_second\n",
    "        USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "    WHERE s.shipping_date <  toDate('{START_DATE}')\n",
    "      AND s.closing_date  >  toDate('{START_DATE}')\n",
    "    GROUP BY s.mp, s.seller, s.article_1c, s.code_1c, s.cluster_to\n",
    ")\n",
    "\n",
    "/* моделируем запас на день D: stock_today = max(0, stock_prev - sales_prev + supplies_arrive_today) */\n",
    ", stocks_sim_today AS (\n",
    "    SELECT\n",
    "        cb.mp, cb.seller, cb.sku, cb.article_1c, cb.code_1c, cb.cluster_to,\n",
    "        GREATEST(\n",
    "            0,\n",
    "            ROUND( cb.quantity_stocks_prev - cb.quantity_orders_prev + IFNULL(sa.quantity_supplies_arrive, 0) )\n",
    "        ) AS quantity_stocks\n",
    "    FROM current_buffer cb\n",
    "    LEFT JOIN supplies_arrive_today sa\n",
    "        USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    ")\n",
    "\n",
    "/* ФИНАЛ */\n",
    "SELECT\n",
    "    CUR_VER                         AS id_ver,\n",
    "    toDate('{START_DATE}')          AS date,\n",
    "    r.name                          AS name,\n",
    "    article_1c                      AS article_1c,\n",
    "    code_1c                         AS code_1c,\n",
    "    mp                              AS mp,\n",
    "    seller                          AS seller,\n",
    "    sku                             AS sku,\n",
    "    cluster_to                      AS cluster_to,\n",
    "\n",
    "    total_quantity_orders           AS total_quantity_orders,\n",
    "    max_quantity_order              AS max_quantity_order,\n",
    "    ROUND(avg_quantity_orders, 2)   AS avg_quantity_orders,\n",
    "    days_oos_number                 AS days_oos_number,\n",
    "    days_bp_number                  AS days_bp_number,\n",
    "\n",
    "    avg_day_to_cluster              AS avg_day_to_cluster,\n",
    "    insurance_reserv_cluster        AS insurance_reserv_cluster,\n",
    "    buffer_cluster_norm             AS buffer_cluster_norm,\n",
    "\n",
    "    buffer_cluster                  AS buffer_cluster,\n",
    "    GREATEST(\n",
    "        0,\n",
    "        ROUND(buffer_cluster - st.quantity_stocks - IFNULL(sit.quantity_supplies, 0))\n",
    "    )                               AS deliveries_to_cluster,\n",
    "    ROUND(\n",
    "        LEAST(\n",
    "            IFNULL( (st.quantity_stocks + IFNULL(sit.quantity_supplies, 0)) / NULLIF(buffer_cluster, 0), 1 ),\n",
    "            1\n",
    "        ),\n",
    "        2\n",
    "    )                               AS buffer_cluster_marker,\n",
    "\n",
    "    IFNULL(ops.quantity_orders, 0)  AS quantity_orders,\n",
    "    st.quantity_stocks              AS quantity_stocks,\n",
    "    IFNULL(sit.quantity_supplies, 0) AS quantity_supplies,\n",
    "    new_buffer                      AS new_buffer\n",
    "\n",
    "FROM current_buffer\n",
    "LEFT JOIN stocks_sim_today        st   USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "LEFT JOIN orders_per_cluster_second ops USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "LEFT JOIN supplies_in_transit     sit  USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "LEFT JOIN (\n",
    "    SELECT DISTINCT name, article_1c, code_1c\n",
    "    FROM ref.article_mp\n",
    "    WHERE discounted != 1 AND brand != 'РЕСЕЙЛ'\n",
    ") r USING (article_1c, code_1c)\n",
    "\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "851cc6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:58.970+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m78} INFO\u001b[0m - Получение данных из БД\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:59.251+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m81} INFO\u001b[0m - Получено 0 строк.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_sim = ch_object.extract_data(query_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d37226eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f58df7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:04:59.296+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m91} INFO\u001b[0m - Вставка 0 записей в sb.buffer_main.\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:04:59.311+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m97} INFO\u001b[0m - Таблица sb.buffer_main содержит 9060 строк после вставки.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_sim, other_column_list = preprocess_data(df=df_sim, column_types=TYPES, add_missed_columns=True, handle_invalid_values=False)\n",
    "ch_object.insert_data(table_name='sb.buffer_main', df=df_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ad6c6",
   "metadata": {},
   "source": [
    "RECAL_DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93c96df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_recalc  = f'''\n",
    "WITH\n",
    "    toInt32({PARAMS['PERIOD']})       AS PERIOD,\n",
    "    toInt32({PARAMS['RECALC_EVERY']}) AS RECALC_EVERY,\n",
    "    toFloat64({PARAMS['OOS_RATIO']})  AS OOS_RATIO,\n",
    "    toInt32({PARAMS['id_ver']})       AS CUR_VER,\n",
    "\n",
    "    -- Пороговые значения зон ДУБ/ТОС и шаги изменения буфера\n",
    "    toFloat64(0.3333333333)           AS Z_RED,\n",
    "    toFloat64(0.6666666667)           AS Z_GREEN,\n",
    "    toFloat64(4.0/3.0)                AS UP_FACTOR,\n",
    "    toFloat64(2.0/3.0)                AS DOWN_FACTOR,\n",
    "    toFloat64(0.50)                   AS UP_SHARE,\n",
    "    toFloat64(0.70)                   AS DOWN_SHARE\n",
    "\n",
    "/* ключи для пересчёта */\n",
    ", key_list_recalc AS (\n",
    "    SELECT DISTINCT mp, seller, sku, article_1c, code_1c, cluster_to\n",
    "    FROM sb.buffer_calc_keys\n",
    "    WHERE date   = toDate('{START_DATE}')\n",
    "      AND id_ver = CUR_VER\n",
    "      AND calc_type = 'recalc_day'\n",
    ")\n",
    "\n",
    "/* состояние на D-1 */\n",
    ", prev_state AS (\n",
    "    SELECT\n",
    "        cb.article_1c               AS article_1c,\n",
    "        cb.code_1c                  AS code_1c,\n",
    "        cb.mp                       AS mp,\n",
    "        cb.seller                   AS seller,\n",
    "        cb.sku                      AS sku,\n",
    "        cb.cluster_to               AS cluster_to,\n",
    "\n",
    "        cb.quantity_stocks          AS quantity_stocks_prev,\n",
    "        cb.quantity_orders          AS quantity_orders_prev,\n",
    "\n",
    "        cb.total_quantity_orders    AS total_quantity_orders_prev,\n",
    "        cb.max_quantity_order       AS max_quantity_order_prev,\n",
    "        cb.avg_quantity_orders      AS avg_quantity_orders_prev,\n",
    "        cb.days_oos_number          AS days_oos_number_prev,\n",
    "        cb.days_bp_number           AS days_bp_number_prev,\n",
    "        cb.avg_day_to_cluster       AS avg_day_to_cluster_prev,\n",
    "        cb.insurance_reserv_cluster AS insurance_reserv_cluster_prev,\n",
    "        cb.buffer_cluster_norm      AS buffer_cluster_norm_prev,\n",
    "\n",
    "        cb.buffer_cluster           AS buffer_cluster_prev,\n",
    "        cb.new_buffer               AS new_buffer_prev\n",
    "    FROM sb.buffer_main cb\n",
    "    INNER JOIN key_list_recalc\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE cb.date   = toDate('{START_DATE}') - INTERVAL 1 DAY\n",
    "      AND cb.id_ver = CUR_VER\n",
    ")\n",
    "\n",
    "/* окно D-RECALC_EVERY .. D-1: смоделированные остатки из buffer_main */\n",
    ", stocks_window_bm AS (\n",
    "    SELECT\n",
    "        bm.date        AS date,\n",
    "        bm.mp          AS mp,\n",
    "        bm.seller      AS seller,\n",
    "        bm.sku         AS sku,\n",
    "        bm.article_1c  AS article_1c,\n",
    "        bm.code_1c     AS code_1c,\n",
    "        bm.cluster_to  AS cluster_to,\n",
    "        bm.quantity_stocks AS quantity_stocks\n",
    "    FROM sb.buffer_main bm\n",
    "    INNER JOIN key_list_recalc\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE bm.id_ver = CUR_VER\n",
    "      AND bm.date  >= toDate('{START_DATE}') - INTERVAL RECALC_EVERY DAY\n",
    "      AND bm.date  <  toDate('{START_DATE}')\n",
    ")\n",
    "\n",
    "/* зоны по окну относительно вчерашнего буфера (в штуках) */\n",
    ", window_zones AS (\n",
    "    SELECT\n",
    "        sw.mp, sw.seller, sw.sku, sw.article_1c, sw.code_1c, sw.cluster_to,\n",
    "        count() AS days_total,\n",
    "        sum( (sw.quantity_stocks <= 0) OR (sw.quantity_stocks / nullIf(ps.buffer_cluster_prev,0) <= OOS_RATIO) ) AS days_oos,\n",
    "        sum( (sw.quantity_stocks / nullIf(ps.buffer_cluster_prev,0)) <= Z_RED )   AS days_red,\n",
    "        sum( (sw.quantity_stocks / nullIf(ps.buffer_cluster_prev,0)) >= Z_GREEN ) AS days_green\n",
    "    FROM stocks_window_bm sw\n",
    "    INNER JOIN prev_state ps\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    GROUP BY sw.mp, sw.seller, sw.sku, sw.article_1c, sw.code_1c, sw.cluster_to\n",
    ")\n",
    "\n",
    "/* решение по ДУБ/ТОС: множитель к вчерашнему buffer_cluster */\n",
    ", tune_decision AS (\n",
    "    SELECT\n",
    "        wz.mp, wz.seller, wz.sku, wz.article_1c, wz.code_1c, wz.cluster_to,\n",
    "        (wz.days_red   / nullIf(toFloat64(wz.days_total),0))   AS share_red,\n",
    "        (wz.days_green / nullIf(toFloat64(wz.days_total),0))   AS share_green,\n",
    "        multiIf(\n",
    "            share_red   >= UP_SHARE,   UP_FACTOR,\n",
    "            share_green >= DOWN_SHARE, DOWN_FACTOR,\n",
    "            1.0\n",
    "        ) AS factor\n",
    "    FROM window_zones wz\n",
    ")\n",
    "\n",
    "/* поставки, прибывающие сегодня (для эволюции запаса) */\n",
    ", supplies_arrive_today AS (\n",
    "    SELECT s.mp AS mp, s.seller AS seller, s.article_1c AS article_1c, s.code_1c AS code_1c,\n",
    "           s.cluster_to AS cluster_to,\n",
    "           SUM(s.quantity_supplies) AS quantity_supplies_arrive\n",
    "    FROM sb.buffer_supplies s\n",
    "    INNER JOIN key_list_recalc\n",
    "        USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "    WHERE s.closing_date = toDate('{START_DATE}')\n",
    "      AND s.shipping_date <= toDate('{START_DATE}')\n",
    "    GROUP BY s.mp, s.seller, s.article_1c, s.code_1c, s.cluster_to\n",
    ")\n",
    "\n",
    "/* поставки «в пути» на сегодня (для маркера и потребности) */\n",
    ", supplies_in_transit_today AS (\n",
    "    SELECT s.mp AS mp, s.seller AS seller, s.article_1c AS article_1c, s.code_1c AS code_1c,\n",
    "           s.cluster_to AS cluster_to,\n",
    "           SUM(s.quantity_supplies) AS quantity_supplies\n",
    "    FROM sb.buffer_supplies s\n",
    "    INNER JOIN key_list_recalc\n",
    "        USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "    WHERE s.shipping_date <  toDate('{START_DATE}')\n",
    "      AND s.closing_date  >  toDate('{START_DATE}')\n",
    "    GROUP BY s.mp, s.seller, s.article_1c, s.code_1c, s.cluster_to\n",
    ")\n",
    "\n",
    "/* моделированный остаток на сегодня: max(0, вчера − продажи_вчера + прибывшие сегодня) */\n",
    ", stock_today AS (\n",
    "    SELECT\n",
    "        ps.mp, ps.seller, ps.sku, ps.article_1c, ps.code_1c, ps.cluster_to,\n",
    "        GREATEST(0, ROUND(ps.quantity_stocks_prev - ps.quantity_orders_prev + IFNULL(sa.quantity_supplies_arrive, 0))) AS quantity_stocks\n",
    "    FROM prev_state ps\n",
    "    LEFT JOIN supplies_arrive_today sa\n",
    "        USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    ")\n",
    "\n",
    "/* реальные заказы на сегодня */\n",
    ", orders_today_raw AS (\n",
    "    SELECT\n",
    "        am.mp AS mp, am.seller AS seller, am.sku AS sku, am.article_1c AS article_1c, am.code_1c AS code_1c, am.cluster_to AS cluster_to,\n",
    "        SUM(am.quantity_orders) AS quantity_orders\n",
    "    FROM kpi.all_mp_sales_wsb am\n",
    "    INNER JOIN key_list_recalc\n",
    "        USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    WHERE am.date = toDate('{START_DATE}')\n",
    "    GROUP BY am.mp, am.seller, am.sku, am.article_1c, am.code_1c, am.cluster_to\n",
    ")\n",
    "\n",
    "/* сим-правило для заказов на сегодня: если нет остатка — обнуляем */\n",
    ", orders_today_sim AS (\n",
    "    SELECT\n",
    "        ps.mp AS mp, ps.seller AS seller, ps.sku AS sku, ps.article_1c AS article_1c, ps.code_1c AS code_1c, ps.cluster_to AS cluster_to,\n",
    "        IF(st.quantity_stocks > 0, IFNULL(ot.quantity_orders, 0), 0) AS quantity_orders\n",
    "    FROM prev_state ps\n",
    "    LEFT JOIN stock_today      st USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "    LEFT JOIN orders_today_raw ot USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    ")\n",
    "\n",
    "/* ФИНАЛ: пересчёт буфера только по ДУБ/ТОС */\n",
    "SELECT\n",
    "    CUR_VER                                   AS id_ver,\n",
    "    toDate('{START_DATE}')                    AS date,\n",
    "    r.name                                    AS name,\n",
    "    article_1c                                AS article_1c,\n",
    "    code_1c                                   AS code_1c,\n",
    "    mp                                        AS mp,\n",
    "    seller                                    AS seller,\n",
    "    sku                                       AS sku,\n",
    "    cluster_to                                AS cluster_to,\n",
    "\n",
    "    total_quantity_orders_prev                AS total_quantity_orders,\n",
    "    max_quantity_order_prev                   AS max_quantity_order,\n",
    "    ROUND(avg_quantity_orders_prev, 2)        AS avg_quantity_orders,\n",
    "    days_oos_number_prev                      AS days_oos_number,\n",
    "    days_bp_number_prev                       AS days_bp_number,\n",
    "\n",
    "    avg_day_to_cluster_prev                   AS avg_day_to_cluster,\n",
    "    insurance_reserv_cluster_prev             AS insurance_reserv_cluster,\n",
    "    buffer_cluster_norm_prev                  AS buffer_cluster_norm,\n",
    "\n",
    "    ROUND(buffer_cluster_prev * td.factor)    AS buffer_cluster,\n",
    "    GREATEST(\n",
    "        0,\n",
    "        ROUND( (buffer_cluster_prev * td.factor) - st.quantity_stocks - IFNULL(sit.quantity_supplies, 0) )\n",
    "    )                                         AS deliveries_to_cluster,\n",
    "    ROUND(\n",
    "        LEAST(\n",
    "            IFNULL( (st.quantity_stocks + IFNULL(sit.quantity_supplies, 0)) / NULLIF(buffer_cluster_prev * td.factor, 0), 1 ),\n",
    "            1\n",
    "        ),\n",
    "        2\n",
    "    )                                         AS buffer_cluster_marker,\n",
    "\n",
    "    ots.quantity_orders                       AS quantity_orders,\n",
    "    st.quantity_stocks                        AS quantity_stocks,\n",
    "    IFNULL(sit.quantity_supplies, 0)          AS quantity_supplies,\n",
    "    0                                         AS new_buffer\n",
    "\n",
    "FROM prev_state\n",
    "INNER JOIN tune_decision             td  USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "LEFT  JOIN stock_today               st  USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "LEFT  JOIN supplies_in_transit_today sit USING (mp, seller, article_1c, code_1c, cluster_to)\n",
    "LEFT  JOIN orders_today_sim          ots USING (mp, seller, sku, article_1c, code_1c, cluster_to)\n",
    "LEFT  JOIN (\n",
    "    SELECT DISTINCT name, article_1c, code_1c\n",
    "    FROM ref.article_mp\n",
    "    WHERE discounted != 1 AND brand != 'РЕСЕЙЛ'\n",
    ") r USING (article_1c, code_1c)\n",
    "\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad1381a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-13T16:42:43.757+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m78} INFO\u001b[0m - Получение данных из БД\u001b[0m\n",
      "[\u001b[34m2025-08-13T16:42:44.492+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m81} INFO\u001b[0m - Получено 8119 строк.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_recalc = ch_object.extract_data(query_recalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3479841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ver</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>article_1c</th>\n",
       "      <th>code_1c</th>\n",
       "      <th>mp</th>\n",
       "      <th>seller</th>\n",
       "      <th>sku</th>\n",
       "      <th>cluster_to</th>\n",
       "      <th>total_quantity_orders</th>\n",
       "      <th>max_quantity_order</th>\n",
       "      <th>avg_quantity_orders</th>\n",
       "      <th>days_oos_number</th>\n",
       "      <th>days_bp_number</th>\n",
       "      <th>avg_day_to_cluster</th>\n",
       "      <th>insurance_reserv_cluster</th>\n",
       "      <th>buffer_cluster_norm</th>\n",
       "      <th>buffer_cluster</th>\n",
       "      <th>deliveries_to_cluster</th>\n",
       "      <th>buffer_cluster_marker</th>\n",
       "      <th>quantity_orders</th>\n",
       "      <th>quantity_stocks</th>\n",
       "      <th>quantity_supplies</th>\n",
       "      <th>new_buffer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone Grey</td>\n",
       "      <td>1096044</td>\n",
       "      <td>УТ000094525</td>\n",
       "      <td>Ozon</td>\n",
       "      <td>Айковер</td>\n",
       "      <td>204694204</td>\n",
       "      <td>Санкт-Петербург и СЗО</td>\n",
       "      <td>144</td>\n",
       "      <td>10</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>61.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>44</td>\n",
       "      <td>979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone Grey</td>\n",
       "      <td>1096044</td>\n",
       "      <td>УТ000094525</td>\n",
       "      <td>Ozon</td>\n",
       "      <td>Айковер</td>\n",
       "      <td>204694204</td>\n",
       "      <td>Беларусь</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>33.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone Grey</td>\n",
       "      <td>1096044</td>\n",
       "      <td>УТ000094525</td>\n",
       "      <td>Ozon</td>\n",
       "      <td>Айковер</td>\n",
       "      <td>204694204</td>\n",
       "      <td>Юг</td>\n",
       "      <td>138</td>\n",
       "      <td>17</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>47</td>\n",
       "      <td>1014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone Grey</td>\n",
       "      <td>1096044</td>\n",
       "      <td>УТ000094525</td>\n",
       "      <td>Ozon</td>\n",
       "      <td>Айковер</td>\n",
       "      <td>204694204</td>\n",
       "      <td>Самара</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone Grey</td>\n",
       "      <td>1096044</td>\n",
       "      <td>УТ000094525</td>\n",
       "      <td>Ozon</td>\n",
       "      <td>Айковер</td>\n",
       "      <td>204694204</td>\n",
       "      <td>Казань</td>\n",
       "      <td>91</td>\n",
       "      <td>8</td>\n",
       "      <td>3.79</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>48.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Тумба RIDBERG LUGANO 2Я Белый/Черный 2шт комплект</td>\n",
       "      <td>1214748</td>\n",
       "      <td>УТ000126894</td>\n",
       "      <td>WB</td>\n",
       "      <td>Ридберг</td>\n",
       "      <td>296165058</td>\n",
       "      <td>Центральный федеральный округ</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Тумба RIDBERG LUGANO 2Я Белый/Золото 2шт комплект</td>\n",
       "      <td>1214749</td>\n",
       "      <td>УТ000126895</td>\n",
       "      <td>WB</td>\n",
       "      <td>Ридберг</td>\n",
       "      <td>296165059</td>\n",
       "      <td>Центральный федеральный округ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone - C Black</td>\n",
       "      <td>gru1760</td>\n",
       "      <td>УТ000104061</td>\n",
       "      <td>WB</td>\n",
       "      <td>Ридберг</td>\n",
       "      <td>113458247</td>\n",
       "      <td>Южный федеральный округ</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone - C Black</td>\n",
       "      <td>gru1760</td>\n",
       "      <td>УТ000104061</td>\n",
       "      <td>WB</td>\n",
       "      <td>Ридберг</td>\n",
       "      <td>113458247</td>\n",
       "      <td>Приволжский федеральный округ</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>Электробритва Enchen BlackStone - C Black</td>\n",
       "      <td>gru1760</td>\n",
       "      <td>УТ000104061</td>\n",
       "      <td>WB</td>\n",
       "      <td>Ридберг</td>\n",
       "      <td>113458247</td>\n",
       "      <td>Центральный федеральный округ</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8119 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_ver       date                                               name  \\\n",
       "0          1 2025-02-08               Электробритва Enchen BlackStone Grey   \n",
       "1          1 2025-02-08               Электробритва Enchen BlackStone Grey   \n",
       "2          1 2025-02-08               Электробритва Enchen BlackStone Grey   \n",
       "3          1 2025-02-08               Электробритва Enchen BlackStone Grey   \n",
       "4          1 2025-02-08               Электробритва Enchen BlackStone Grey   \n",
       "...      ...        ...                                                ...   \n",
       "8114       1 2025-02-08  Тумба RIDBERG LUGANO 2Я Белый/Черный 2шт комплект   \n",
       "8115       1 2025-02-08  Тумба RIDBERG LUGANO 2Я Белый/Золото 2шт комплект   \n",
       "8116       1 2025-02-08          Электробритва Enchen BlackStone - C Black   \n",
       "8117       1 2025-02-08          Электробритва Enchen BlackStone - C Black   \n",
       "8118       1 2025-02-08          Электробритва Enchen BlackStone - C Black   \n",
       "\n",
       "     article_1c      code_1c    mp   seller        sku  \\\n",
       "0       1096044  УТ000094525  Ozon  Айковер  204694204   \n",
       "1       1096044  УТ000094525  Ozon  Айковер  204694204   \n",
       "2       1096044  УТ000094525  Ozon  Айковер  204694204   \n",
       "3       1096044  УТ000094525  Ozon  Айковер  204694204   \n",
       "4       1096044  УТ000094525  Ozon  Айковер  204694204   \n",
       "...         ...          ...   ...      ...        ...   \n",
       "8114    1214748  УТ000126894    WB  Ридберг  296165058   \n",
       "8115    1214749  УТ000126895    WB  Ридберг  296165059   \n",
       "8116    gru1760  УТ000104061    WB  Ридберг  113458247   \n",
       "8117    gru1760  УТ000104061    WB  Ридберг  113458247   \n",
       "8118    gru1760  УТ000104061    WB  Ридберг  113458247   \n",
       "\n",
       "                         cluster_to  total_quantity_orders  \\\n",
       "0             Санкт-Петербург и СЗО                    144   \n",
       "1                          Беларусь                     39   \n",
       "2                                Юг                    138   \n",
       "3                            Самара                     71   \n",
       "4                            Казань                     91   \n",
       "...                             ...                    ...   \n",
       "8114  Центральный федеральный округ                      3   \n",
       "8115  Центральный федеральный округ                      2   \n",
       "8116        Южный федеральный округ                     13   \n",
       "8117  Приволжский федеральный округ                      2   \n",
       "8118  Центральный федеральный округ                     17   \n",
       "\n",
       "      max_quantity_order  avg_quantity_orders  days_oos_number  \\\n",
       "0                     10                 4.80                0   \n",
       "1                      4                 1.30                0   \n",
       "2                     17                 4.60                0   \n",
       "3                      9                 2.37                0   \n",
       "4                      8                 3.79                6   \n",
       "...                  ...                  ...              ...   \n",
       "8114                   1                 0.12                6   \n",
       "8115                   1                 0.08                6   \n",
       "8116                   2                 0.43                0   \n",
       "8117                   2                 0.29               23   \n",
       "8118                   2                 0.57                0   \n",
       "\n",
       "      days_bp_number  avg_day_to_cluster  insurance_reserv_cluster  \\\n",
       "0                  0                7.00                        12   \n",
       "1                  0                7.00                        12   \n",
       "2                  0                7.00                        12   \n",
       "3                  0                7.00                        12   \n",
       "4                  0                7.00                        12   \n",
       "...              ...                 ...                       ...   \n",
       "8114               0                7.00                        12   \n",
       "8115               0                7.00                        12   \n",
       "8116               0                7.00                        12   \n",
       "8117               0                7.00                        12   \n",
       "8118               0                7.00                        12   \n",
       "\n",
       "      buffer_cluster_norm  buffer_cluster  deliveries_to_cluster  \\\n",
       "0                      19           61.00                   0.00   \n",
       "1                      19           33.00                  33.00   \n",
       "2                      19           58.00                   0.00   \n",
       "3                      19           30.00                   0.00   \n",
       "4                      19           48.00                  48.00   \n",
       "...                   ...             ...                    ...   \n",
       "8114                   19            1.00                   0.00   \n",
       "8115                   19            1.00                   0.00   \n",
       "8116                   19            5.00                   0.00   \n",
       "8117                   19            8.00                   3.00   \n",
       "8118                   19            7.00                   0.00   \n",
       "\n",
       "      buffer_cluster_marker  quantity_orders  quantity_stocks  \\\n",
       "0                      1.00               44              979   \n",
       "1                      0.00                0                0   \n",
       "2                      1.00               47             1014   \n",
       "3                      1.00               19              528   \n",
       "4                      0.00                0                0   \n",
       "...                     ...              ...              ...   \n",
       "8114                   1.00                2               62   \n",
       "8115                   1.00                2               57   \n",
       "8116                   1.00                3              200   \n",
       "8117                   0.62                0                0   \n",
       "8118                   1.00                2              395   \n",
       "\n",
       "      quantity_supplies  new_buffer  \n",
       "0                     0           0  \n",
       "1                     0           0  \n",
       "2                     0           0  \n",
       "3                     0           0  \n",
       "4                     0           0  \n",
       "...                 ...         ...  \n",
       "8114                  0           0  \n",
       "8115                  0           0  \n",
       "8116                  0           0  \n",
       "8117                  5           0  \n",
       "8118                  0           0  \n",
       "\n",
       "[8119 rows x 24 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1179dbf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Отсутствуют обязательные столбцы: ['article_1c', 'deliveries_to_cluster', 'quantity_stocks', 'id_ver', 'max_quantity_order', 'avg_quantity_orders', 'days_bp_number', 'seller', 'cluster_to', 'buffer_cluster', 'code_1c', 'buffer_cluster_norm', 'avg_day_to_cluster', 'total_quantity_orders', 'sku', 'name', 'new_buffer', 'days_oos_number', 'mp', 'date', 'insurance_reserv_cluster', 'quantity_orders', 'buffer_cluster_marker', 'quantity_supplies']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_recalc, other_column_list \u001b[38;5;241m=\u001b[39m preprocess_data(df\u001b[38;5;241m=\u001b[39mdf_recalc, column_types\u001b[38;5;241m=\u001b[39mTYPES, add_missed_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, handle_invalid_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m ch_object\u001b[38;5;241m.\u001b[39minsert_data(table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msb.buffer_main\u001b[39m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m=\u001b[39mdf_recalc)\n",
      "File \u001b[1;32m\\\\sigma.icover.ru\\share\\Аналитика\\Скрипты\\Сливин\\plugins\\preprocess_data_2.py:181\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df, column_types, rename_columns, add_missed_columns, handle_invalid_values)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Обработка отсутствующих столбцов\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_missed_columns:\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОтсутствуют обязательные столбцы: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# 3. Добавление отсутствующих столбцов\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_columns \u001b[38;5;129;01mand\u001b[39;00m add_missed_columns:\n",
      "\u001b[1;31mValueError\u001b[0m: Отсутствуют обязательные столбцы: ['article_1c', 'deliveries_to_cluster', 'quantity_stocks', 'id_ver', 'max_quantity_order', 'avg_quantity_orders', 'days_bp_number', 'seller', 'cluster_to', 'buffer_cluster', 'code_1c', 'buffer_cluster_norm', 'avg_day_to_cluster', 'total_quantity_orders', 'sku', 'name', 'new_buffer', 'days_oos_number', 'mp', 'date', 'insurance_reserv_cluster', 'quantity_orders', 'buffer_cluster_marker', 'quantity_supplies']"
     ]
    }
   ],
   "source": [
    "df_recalc, other_column_list = preprocess_data(df=df_recalc, column_types=TYPES, add_missed_columns=False, handle_invalid_values=False)\n",
    "ch_object.insert_data(table_name='sb.buffer_main', df=df_recalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3727bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date = '2025-02-01'\n",
    "extract_by_theory = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM sb.buffer_main\n",
    "    WHERE id_ver = '{PARAMS['id_ver']}' AND date = '{START_DATE}'\n",
    "\"\"\"\n",
    "\n",
    "# Пока в sb.buffer_main присутствуют дубли, возьмем уникальные нужные нам строки\n",
    "# extract_by_theory = f\"\"\"\n",
    "#     SELECT *\n",
    "#     FROM (SELECT *, \n",
    "#         ROW_NUMBER()\tOVER (PARTITION BY mp, seller, cluster_to, sku ORDER BY date DESC) AS rank\n",
    "#     FROM sb.buffer_main)\n",
    "#     WHERE rank = 1\n",
    "# \"\"\"\n",
    "buffer_main = ch_object.extract_data(extract_by_theory)\n",
    "len(buffer_main)\n",
    "\n",
    "\n",
    "query_volumes = \"\"\"\n",
    "    SELECT DISTINCT article_1c, code_1c, mp, seller, volume_m3 \n",
    "    FROM ref.article_mp\n",
    "    WHERE volume_m3 != ''\n",
    "\"\"\"\n",
    "volumes = ch_object.extract_data(query=query_volumes)\n",
    "\n",
    "volumes = volumes.astype({'volume_m3': 'float'})\n",
    "volumes.info()\n",
    "\n",
    "\n",
    "\n",
    "min_cluster_m3 = PARAMS['min_cluster_m3'] \n",
    "min_good = PARAMS['min_good'] \n",
    "min_cluster_limit = PARAMS['min_cluster_limit']\n",
    "# отсечка по количеству на один вид товара\n",
    "buffer_main = buffer_main[buffer_main['deliveries_to_cluster'] >= min_good]\n",
    "\n",
    "merged_df = buffer_main.merge(right=volumes, how='left', on=['article_1c', 'code_1c', 'mp', 'seller'])\n",
    "merged_df['volume_requirement'] = merged_df['deliveries_to_cluster'] * merged_df['volume_m3']\n",
    "\n",
    "empty_vol = merged_df[merged_df['volume_m3'].isna()]\n",
    "print(f'Количество строк с пустым объемом: {len(empty_vol)}')\n",
    "if len(empty_vol):\n",
    "    empty_vol.head()\n",
    "\n",
    "# будем работать только с непустым объемом\n",
    "df = merged_df[merged_df['volume_m3'].notna()]\n",
    "logging.info(f'Количество строк, по которым будут сформированны поставки: {len(df)}')\n",
    "\n",
    "assignments, skipped = [], []\n",
    "\n",
    "# находим максимально необходимое количество машин по каждой поставке \n",
    "for wh, wh_items in df.groupby(by=['mp', 'seller', 'cluster_to']): #.query('(cluster_to == \"Приволжский федеральный округ\") & (seller == \"Ридберг\")')\n",
    "    print(wh)\n",
    "    # Рандомим дату отправки и дату прибытия\n",
    "    # shipping_date = datetime.today() + timedelta(days=random.randint(5, 20))\n",
    "    # closing_date = wh_items['date'] + timedelta(days=random.randint(7, 10))\n",
    "\n",
    "    total_vol = wh_items['volume_requirement'].sum() # объем поставки\n",
    "    print(f\"объем поставки: {total_vol}\")\n",
    "    if total_vol < min_cluster_limit:\n",
    "        print(f\"поставка меньше 8 м куб - не едет\")\n",
    "        continue # поставка меньше 8 м куб - не едет\n",
    "\n",
    "    truck_count = int(math.floor(total_vol / min_cluster_m3)) # кол-во машин по 8 м3\n",
    "    print(f\"Количество целых заполненных машин: {truck_count}\")\n",
    "    # if truck_count == 0:\n",
    "    #     continue  # не должно случиться, но пусть будет\n",
    "\n",
    "    # Важно ли нам знать номер машины, в которой поедет тот или иной товар? если нет, тогда:\n",
    "    full_vol = truck_count * min_cluster_m3 # объем полностью загруженных машин\n",
    "\n",
    "    # Сделаем проверку, что последняя машина не должна быть заполнениться меньше, чем 8 кубов, \n",
    "    # иначе можно грузить, не заполняя последнюю машину полностью\n",
    "    if total_vol - full_vol >= PARAMS['min_cluster_limit']: # остаток свободного места меньше, чем 2 куба\n",
    "        full_vol = total_vol \n",
    "        print(f\"Последняя машина заполняется на {total_vol - full_vol} что >= {PARAMS['min_cluster_limit']} остаток свободного места меньше, чем 2 куба, можно грузить, не заполняя последнюю машину полностью\")\n",
    "\n",
    "    # объём, оставшийся в текущей машине (да, я создаю 100500 объектов, и что. Потом оптимизирую)\n",
    "    free_left = full_vol\n",
    "    print(f\"Объем итоговый поставки: {free_left}\")\n",
    "\n",
    "    # Идём по товарам в порядке убывания приоритета (нашего светофора)\n",
    "    for _, row in wh_items.sort_values('buffer_cluster_marker', ascending=False).iterrows():\n",
    "        # vol = row['volume_requirement']\n",
    "\n",
    "        # Базовый словарь параметров\n",
    "        base_params = {\n",
    "                        'id_ver': row['id_ver'],                    # рандомим\n",
    "                        'supply_id': \"_\".join(str(i) for i in wh),  # рандомим\n",
    "                        'shipping_date': row['date'],\n",
    "                        'closing_date': row['date'] + timedelta(days=random.randint(7, 10)),               # рандомим\n",
    "                        'article_1c': row['article_1c'],\n",
    "                        'code_1c': row['code_1c'],\n",
    "                        'mp': row['mp'], \n",
    "                        'seller': row['seller'], \n",
    "                        'sku': row['sku'],\n",
    "                        'cluster_to': row['cluster_to'],           \n",
    "                        'quantity_supplies': row['deliveries_to_cluster'],\n",
    "                        # 'volume_m3': row['volume_m3'],                            # закомментить\n",
    "                        'loaded_volume': row['volume_requirement'],               # закомментить\n",
    "                        # 'buffer_cluster_marker': row['buffer_cluster_marker']     # закомментить\n",
    "                    }\n",
    "        # Если влазит в оставшееся место\n",
    "        if row['volume_requirement'] <= free_left:\n",
    "            assignments.append(base_params)\n",
    "            free_left -= row['volume_requirement']\n",
    "        else:\n",
    "            # обработка логики, когда отправляем не полный объем товара\n",
    "            half_quantity = int(math.floor(free_left / row['volume_m3'])) # целое количество на оставшееся свободное место\n",
    "            if half_quantity >= min_good:\n",
    "                assignments.append({\n",
    "                    **base_params,\n",
    "                    'quantity_supplies': half_quantity,\n",
    "                    'loaded_volume': half_quantity * row['volume_m3'],             # закомментить\n",
    "                })\n",
    "                free_left -= half_quantity * row['volume_m3']\n",
    "                \n",
    "                skipped.append({\n",
    "                    **base_params,\n",
    "                    'quantity_supplies': row['deliveries_to_cluster'] - half_quantity, # сколько НЕ отправили\n",
    "                    'loaded_volume': (row['deliveries_to_cluster'] - half_quantity) * row['volume_m3'],             # закомментить\n",
    "                })\n",
    "            else:\n",
    "                skipped.append({\n",
    "                    **base_params,\n",
    "                    'quantity_supplies': row['deliveries_to_cluster'], # сколько НЕ отправили\n",
    "                    })\n",
    "                \n",
    "\n",
    "assignments_df, skipped_df = pd.DataFrame(assignments), pd.DataFrame(skipped)\n",
    "\n",
    "TYPES_SUP = {\n",
    "        'id_ver': 'str',\n",
    "        'supply_id': 'str',\n",
    "        'shipping_date': 'datetime64[ns]',\n",
    "        'closing_date': 'datetime64[ns]',\n",
    "        'article_1c': 'str',\n",
    "        'code_1c': 'str',\n",
    "        'mp': 'str',\n",
    "        'seller': 'str',\n",
    "        'sku': 'str',\n",
    "        'cluster_to':'str',\n",
    "        'quantity_supplies': 'int'\n",
    "}\n",
    "\n",
    "ch_object.execute_query(query=f'''ALTER TABLE sb.buffer_supplies DELETE WHERE id_ver = '{PARAMS['id_ver']}' AND shipping_date = '{START_DATE}'  ''')\n",
    "ch_object.insert_data(table_name='sb.buffer_supplies', df=assignments_df[TYPES_SUP.keys()].astype(dtype=TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4f3725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-08-14T13:50:03.433+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m140} INFO\u001b[0m - Выполнение произвольного запроса: TRUNCATE TABLE sb.buffer_main\u001b[0m\n",
      "[\u001b[34m2025-08-14T13:50:03.492+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m140} INFO\u001b[0m - Выполнение произвольного запроса: TRUNCATE TABLE sb.buffer_calc_keys\u001b[0m\n",
      "[\u001b[34m2025-08-14T13:50:03.529+0300\u001b[0m] {\u001b[34mConnectingOperator.py:\u001b[0m140} INFO\u001b[0m - Выполнение произвольного запроса: TRUNCATE TABLE sb.buffer_supplies\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 20695871, 'aff14489-b22c-4c32-a203-01b52c6014cf']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_object.execute_query(query=\"TRUNCATE TABLE sb.buffer_main\")\n",
    "ch_object.execute_query(query=\"TRUNCATE TABLE sb.buffer_calc_keys\")\n",
    "ch_object.execute_query(query=\"TRUNCATE TABLE sb.buffer_supplies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46586f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
